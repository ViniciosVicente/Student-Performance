# ğŸ“ Student Performance Prediction

Este projeto tem como objetivo prever o desempenho acadÃªmico de estudantes com base em fatores como condiÃ§Ã£o socioeconÃ´mica, horas de estudo, sono e frequÃªncia escolar, utilizando tÃ©cnicas de Machine Learning.

## ğŸ“ Dataset

- **Fonte**: [Predict Student Performance Dataset - Kaggle](https://www.kaggle.com/datasets/stealthtechnologies/predict-student-performance-dataset)
- **DescriÃ§Ã£o**: O dataset Ã© sintÃ©tico, com 1.388 registros e 5 colunas numÃ©ricas. Cada linha representa um estudante.

### ğŸ“Œ Colunas do Dataset

| Coluna               | DescriÃ§Ã£o                                               |
|----------------------|----------------------------------------------------------|
| `Socioeconomic Score`| Ãndice que reflete a condiÃ§Ã£o socioeconÃ´mica do estudante |
| `Study Hours`        | MÃ©dia de horas de estudo por dia                          |
| `Sleep Hours`        | MÃ©dia de horas de sono por noite                          |
| `Attendance (%)`     | Percentual de presenÃ§a nas aulas                          |
| `Grades`             | Nota final do estudante (variÃ¡vel alvo)                  |

---

## ğŸ¤– Modelos Utilizados

Treinamos trÃªs modelos de regressÃ£o supervisionada para prever a nota final (`Grades`):

1. **Random Forest Regressor**
2. **K-Nearest Neighbors (KNN)**
3. **Rede Neural com TensorFlow (Sequential API)**

---

## âš™ï¸ MÃ©tricas de AvaliaÃ§Ã£o

Para comparar o desempenho dos modelos de machine learning, utilizamos trÃªs mÃ©tricas principais:

- **MAE (Mean Absolute Error)**  
  Mede o erro mÃ©dio absoluto entre as previsÃµes e os valores reais.  
  > *Quanto menor, melhor.* Representa o erro mÃ©dio em unidades da variÃ¡vel de saÃ­da.

- **MSE (Mean Squared Error)**  
  Calcula o erro quadrÃ¡tico mÃ©dio, penalizando com mais intensidade erros maiores.  
  > *Quanto menor, melhor.* Erros grandes tÃªm impacto mais significativo.

- **RÂ² (Coeficiente de DeterminaÃ§Ã£o)**  
  Indica o quanto do comportamento da variÃ¡vel dependente Ã© explicado pelo modelo.  
  > *Varia de 0 a 1.* Quanto mais prÃ³ximo de 1, melhor o desempenho explicativo do modelo.

### ğŸ“Š Resultados

| Modelo              | MAE    | MSE     | RÂ²        |
|---------------------|--------|---------|-----------|
| Random Forest       | 1.33   | 3.78    | 0.9590    |
| KNN                 | 2.57   | 17.44   | 0.8080    |
| TensorFlow (Rede Neural) | 1.72   | 4.79    | 0.9473    |

---

## ğŸ“ˆ ConclusÃµes

- A **Random Forest** obteve o melhor desempenho geral, com menor MSE e maior RÂ².
- A **rede neural com TensorFlow** tambÃ©m apresentou bons resultados, com performance prÃ³xima da Random Forest.
- O **KNN** teve o pior desempenho entre os trÃªs modelos, mostrando maior erro e menor capacidade explicativa, possivelmente devido Ã  sensibilidade Ã  escala e ao valor de K.

---

## ğŸš€ PossÃ­veis Melhorias

- Testar outros algoritmos como XGBoost, SVR ou LightGBM
- Ajuste fino de hiperparÃ¢metros com GridSearchCV ou RandomizedSearchCV
- Cross-validation para validar generalizaÃ§Ã£o
- AnÃ¡lise de importÃ¢ncia das variÃ¡veis (especialmente com Random Forest)

---

## ğŸ“ Requisitos

- Python 3.12.7
- Pandas, Scikit-learn, TensorFlow, NumPy, Matplotlib, Seaborn

---


